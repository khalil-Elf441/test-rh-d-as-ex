{
  "examId": "ex316-5",
  "title": "OpenShift Virtualization Specialist (EX316) — Mock 5: Final Version",
  "description": "A comprehensive exam covering a wide range of objectives, requiring you to switch between different skill sets quickly.",
  "timeLimit": "4h",
  "prerequisites": "# This script should be run once before starting the exam.\n\necho \"Creating prerequisite resources for Mock 5...\"\n\n# No specific cluster-wide prerequisites for this mock.\n\necho \"Prerequisite setup complete.\"\n",
  "tasks": [
    {
      "id": "task01",
      "title": "Deploy a multi-tier application across three namespaces",
      "solution": "# 1. Create Namespaces\noc create namespace frontend-prod\noc create namespace api-prod\noc create namespace db-prod\n\n# 2. Deploy Frontend VM\noc process -n openshift rhel9 --param NAME=frontend-vm | oc create -n frontend-prod -f -\n# Then, access the VM console to install nginx\n# oc console frontend-vm -n frontend-prod\n# sudo dnf install -y nginx && sudo systemctl enable --now nginx\n\n# 3. Deploy API VM\noc process -n openshift rhel9 --param NAME=api-vm | oc create -n api-prod -f -\n# Then, access the VM console to install flask\n# oc console api-vm -n api-prod\n# sudo dnf install -y python3-flask\n\n# 4. Deploy DB VM\noc process -n openshift rhel9 --param NAME=db-vm | oc create -n db-prod -f -\n# Then, access the VM console to install redis\n# oc console db-vm -n db-prod\n# sudo dnf install -y redis && sudo systemctl enable --now redis\n",
      "sections": [
        {
          "title": "Web, API, and Database Tiers",
          "notice": "Deploy a web server, an API server, and a database, each in its own namespace: 'frontend-prod', 'api-prod', and 'db-prod'.",
          "subtasks": [
            "Create the three namespaces: 'frontend-prod', 'api-prod', and 'db-prod'.",
            "In 'frontend-prod', deploy a VM named 'frontend-vm' and install 'nginx'.",
            "In 'api-prod', deploy a VM named 'api-vm' and install a basic Python Flask application.",
            "In 'db-prod', deploy a VM named 'db-vm' and install 'redis'."
          ]
        }
      ]
    },
    {
      "id": "task02",
      "title": "Configure networking and security between the application tiers",
      "solution": "# 1. Create API Service\noc expose vm api-vm --name=api-svc --port=5000 --target-port=5000 -n api-prod\n\n# 2. Create DB Service\noc expose vm db-vm --name=db-svc --port=6379 --target-port=6379 -n db-prod\n\n# 3. Create API Network Policy\noc create -f - -n api-prod <<EOF\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-frontend-to-api\nspec:\n  podSelector:\n    matchLabels:\n      kubevirt.io/domain: api-vm\n  policyTypes: [Ingress]\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          kubernetes.io/metadata.name: frontend-prod\nEOF\n\n# 4. Create DB Network Policy\noc create -f - -n db-prod <<EOF\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-api-to-db\nspec:\n  podSelector:\n    matchLabels:\n      kubevirt.io/domain: db-vm\n  policyTypes: [Ingress]\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          kubernetes.io/metadata.name: api-prod\nEOF\n",
      "sections": [
        {
          "title": "Services and Network Policies",
          "notice": "The frontend must talk to the API, and the API must talk to the database. No other communication should be allowed.",
          "subtasks": [
            "In 'api-prod', create a ClusterIP service for 'api-vm' on port 5000.",
            "In 'db-prod', create a ClusterIP service for 'db-vm' on port 6379.",
            "Create a NetworkPolicy in 'api-prod' to only allow ingress from 'frontend-prod'.",
            "Create a NetworkPolicy in 'db-prod' to only allow ingress from 'api-prod'."
          ]
        }
      ]
    },
    {
      "id": "task03",
      "title": "Configure persistent storage for the database",
      "solution": "# 1. Add Volume\noc virt addvolume db-vm --volume-name=redis-data --claim-size=10Gi -n db-prod\n\n# 2. Stop and Start VM for disk to be attached\noc virt stop db-vm -n db-prod\noc virt start db-vm -n db-prod\n\n# 3. Configure disk inside VM\n# oc console db-vm -n db-prod\n# sudo -i\n# mkfs.xfs /dev/vdb\n# mkdir -p /var/lib/redis/data\n# mount /dev/vdb /var/lib/redis/data\n# echo \"/dev/vdb /var/lib/redis/data xfs defaults 0 0\" >> /etc/fstab\n\n# 4. Configure Redis to use the new path (edit /etc/redis.conf)\n# ...\n",
      "sections": [
        {
          "title": "Disk Management",
          "notice": "Add a dedicated disk for Redis data on 'db-vm'. Perform actions in the 'db-prod' namespace.",
          "subtasks": [
            "Create a 10Gi PVC named 'redis-data-pvc'.",
            "Attach this PVC as a data volume to the 'db-vm'.",
            "Log into the 'db-vm' and configure Redis to use the new disk for its data directory.",
            "Ensure the configuration is persistent across reboots."
          ]
        }
      ]
    },
    {
      "id": "task04",
      "title": "Create a custom template from the API server VM",
      "solution": "# 1. Create Namespace\noc create namespace app-templates\n\n# 2. Find source PVC\nSOURCE_PVC=$(oc get dv -n api-prod -l kubevirt.io/domain=api-vm -o jsonpath='{.items[0].metadata.name}')\n\n# 3. Create Template\noc create -f - -n app-templates <<EOF\napiVersion: template.openshift.io/v1\nkind: Template\nmetadata:\n  name: api-server-template\nobjects:\n- apiVersion: kubevirt.io/v1\n  kind: VirtualMachine\n  metadata:\n    name: \"${NAME}\"\n    labels:\n      app.version: \"${APP_VERSION}\"\n  spec:\n    dataVolumeTemplates:\n    - apiVersion: cdi.kubevirt.io/v1beta1\n      kind: DataVolume\n      metadata:\n        name: \"${NAME}-rootdisk\"\n      spec:\n        source:\n          pvc:\n            name: $SOURCE_PVC\n            namespace: api-prod\n    template: {}\nparameters:\n- name: NAME\n  required: true\n- name: APP_VERSION\n  value: \"1.0\"\nEOF\n",
      "sections": [
        {
          "title": "Template Generation",
          "notice": "Create a reusable template from the configured 'api-vm'. Perform actions in a new 'app-templates' namespace.",
          "subtasks": [
            "Create a new namespace named 'app-templates'.",
            "Generate a new template named 'api-server-template' from the 'api-vm'.",
            "Add a parameter to the template for the application version, to be used as a label on the VM.",
            "Verify the template creation."
          ]
        }
      ]
    },
    {
      "id": "task05",
      "title": "Deploy a staging version of the API server from the template",
      "solution": "# 1. Create Namespace\noc create namespace api-staging\n\n# 2. Deploy from Template with Parameters\noc new-app --template=app-templates/api-server-template --param=NAME=api-staging-vm --param=APP_VERSION=v1.1-staging -n api-staging\n\n# 3. Add cloud-init data via patch\noc patch vm api-staging-vm -n api-staging --type merge -p '{\"spec\":{\"template\":{\"spec\":{\"volumes\":[{\"name\":\"cloudinitdisk\",\"cloudInitNoCloud\":{\"userData\":\"#cloud-config\\nvwrite_files:\\n- path: /etc/app_version\\n  content: staging\"}}]}}}}'\n\n# 4. Start the VM\noc virt start api-staging-vm -n api-staging\n",
      "sections": [
        {
          "title": "Template Deployment with Cloud-Init",
          "notice": "Deploy a staging API server in a new 'api-staging' namespace and use cloud-init to set a version flag.",
          "subtasks": [
            "Create a new namespace named 'api-staging'.",
            "Deploy a new VM named 'api-staging-vm' from the 'api-server-template'.",
            "Provide 'v1.1-staging' as the application version parameter during deployment.",
            "Use cloud-init to create a file '/etc/app_version' with the content 'staging'."
          ]
        }
      ]
    },
    {
      "id": "task06",
      "title": "Perform a snapshot and restore of the staging API server",
      "solution": "# 1. Create Snapshot\noc create -f - -n api-staging <<EOF\napiVersion: snapshot.kubevirt.io/v1alpha1\nkind: VirtualMachineSnapshot\nmetadata:\n  name: api-staging-snap\nspec:\n  source:\n    apiGroup: kubevirt.io\n    kind: VirtualMachine\n    name: api-staging-vm\nEOF\n\n# 2. Wait for snapshot to be ready\noc wait --for=condition=Ready vmsnapshot/api-staging-snap -n api-staging --timeout=300s\n\n# 3. Delete VM\noc delete vm api-staging-vm -n api-staging\n\n# 4. Restore VM\noc create -f - -n api-staging <<EOF\napiVersion: snapshot.kubevirt.io/v1alpha1\nkind: VirtualMachineRestore\nmetadata:\n  name: api-staging-restore\nspec:\n  target:\n    apiGroup: kubevirt.io\n    kind: VirtualMachine\n    name: api-staging-vm\n  virtualMachineSnapshotName: api-staging-snap\nEOF\n",
      "sections": [
        {
          "title": "Snapshot and Restore",
          "notice": "Test disaster recovery on the staging VM. Perform actions in the 'api-staging' namespace.",
          "subtasks": [
            "Create a snapshot of 'api-staging-vm'.",
            "Delete the VM after the snapshot is complete.",
            "Restore the VM from the snapshot.",
            "Verify the VM is running correctly."
          ]
        }
      ]
    },
    {
      "id": "task07",
      "title": "Clone the production database for development use",
      "solution": "# 1. Create Namespace\noc create namespace db-dev\n\n# 2. Create Clone CR with target namespace\noc create -f - -n db-prod <<EOF\napiVersion: snapshot.kubevirt.io/v1alpha1\nkind: VirtualMachineClone\nmetadata:\n  name: db-dev-clone\nspec:\n  source:\n    kind: VirtualMachine\n    name: db-vm\n  target:\n    name: db-dev-clone\n    namespace: db-dev\nEOF\n\n# 3. Verify\noc get vm db-dev-clone -n db-dev\n",
      "sections": [
        {
          "title": "VM Cloning",
          "notice": "Create a clone of the production database 'db-vm' for developers in a new 'db-dev' namespace.",
          "subtasks": [
            "Create a new namespace named 'db-dev'.",
            "Clone the 'db-vm' from the 'db-prod' namespace into the 'db-dev' namespace.",
            "Name the new VM 'db-dev-clone'.",
            "Ensure the clone starts and is functional."
          ]
        }
      ]
    },
    {
      "id": "task08",
      "title": "Perform a live migration of the production frontend",
      "solution": "# 1. Initiate Migration\noc virt migrate frontend-vm -n frontend-prod\n\n# 2. Monitor Migration\noc get vmim -n frontend-prod -w\n\n# 3. Verify new node\n# oc get pod -l kubevirt.io/domain=frontend-vm -n frontend-prod -o wide\n",
      "sections": [
        {
          "title": "Live Migration",
          "notice": "The node hosting 'frontend-vm' needs urgent maintenance. Migrate the VM without downtime.",
          "subtasks": [
            "Initiate a live migration for the 'frontend-vm'.",
            "Monitor the migration process to ensure it completes successfully.",
            "Confirm the VM is running on a different node.",
            "Ensure the application remains accessible during the migration."
          ]
        }
      ]
    },
    {
      "id": "task09",
      "title": "Configure RBAC for a frontend developer",
      "solution": "# 1. Create User\noc create user frontend-dev\n\n# 2. Create Role\noc create role vm-admin -n frontend-prod --verb=* --resource=virtualmachines,virtualmachineinstances,datavolumes,virtualmachineclones,virtualmachinesnapshots,virtualmachinerestores\n\n# 3. Create RoleBinding\noc create rolebinding frontend-dev-binding --role=vm-admin --user=frontend-dev -n frontend-prod\n\n# 4. Verify (as user)\n# oc login -u frontend-dev\n# oc get vm -n frontend-prod # (Should succeed)\n# oc get vm -n db-prod # (Should fail)\n",
      "sections": [
        {
          "title": "User Access Control",
          "notice": "Create a user 'frontend-dev' who can only manage VMs in the 'frontend-prod' namespace.",
          "subtasks": [
            "Create a user named 'frontend-dev'.",
            "Create a Role in the 'frontend-prod' namespace that grants full control over VirtualMachine resources.",
            "Bind this Role to the 'frontend-dev' user in that namespace.",
            "Verify the user cannot access VMs in other namespaces like 'db-prod'."
          ]
        }
      ]
    },
    {
      "id": "task10",
      "title": "Configure a health probe for the API server",
      "solution": "# 1. Add Liveness Probe via patch\noc patch vm api-vm -n api-prod --type=json -p '[{\"op\": \"add\", \"path\": \"/spec/template/spec/livenessProbe\", \"value\": {\"httpGet\": {\"port\": 5000, \"path\": \"/health\"}, \"initialDelaySeconds\": 60}}]'\n\n# 2. Verify\n# oc get vm api-vm -n api-prod -o yaml\n",
      "sections": [
        {
          "title": "Liveness Probe",
          "notice": "Ensure the 'api-vm' is automatically restarted if the Flask application is unresponsive.",
          "subtasks": [
            "Edit the 'api-vm' VirtualMachine resource.",
            "Add a liveness probe.",
            "The probe should perform an HTTP GET request on port 5000.",
            "Set a suitable initial delay for the probe."
          ]
        }
      ]
    },
    {
      "id": "task11",
      "title": "Expose the frontend with a Route",
      "solution": "# 1. Create Service\noc expose vm frontend-vm --name=frontend-svc --port=80 --target-port=80 -n frontend-prod\n\n# 2. Create Route\noc create route edge --service=frontend-svc --port=80 -n frontend-prod\n\n# 3. Verify\n# oc get route frontend-vm -n frontend-prod\n# curl http://<route-host>\n",
      "sections": [
        {
          "title": "External Access",
          "notice": "Expose the 'frontend-vm' externally using a Route. Perform actions in the 'frontend-prod' namespace.",
          "subtasks": [
            "Create a ClusterIP service for 'frontend-vm' on port 80.",
            "Create a Route that exposes this service to the public.",
            "Verify the route is created and accessible.",
            "Ensure the route uses the default TLS termination policy."
          ]
        }
      ]
    },
    {
      "id": "task12",
      "title": "Install a custom package on the API server",
      "solution": "# This task is performed inside the VM.\n# 1. Access the VM\noc console api-vm -n api-prod\n\n# 2. Create repo file\nsudo -i\necho -e \"[perf-tools]\\nname=Performance Tools\\nbaseurl=http://repo.example.com/perf_tools\\nenabled=1\\ngpgcheck=0\" > /etc/yum.repos.d/perf.repo\n\n# 3. Install package\ndnf install -y htop\n\n# 4. Verify\nwhich htop\n",
      "sections": [
        {
          "title": "System Administration",
          "notice": "Install a performance monitoring tool from a custom repository on the 'api-vm'. Repo details: URL: http://repo.example.com/perf_tools, File: /etc/yum.repos.d/perf.repo, Content: [perf-tools]...",
          "subtasks": [
            "Log into the 'api-vm'.",
            "Configure the custom repository as specified.",
            "Install the 'htop' package.",
            "Confirm the package is installed."
          ]
        }
      ]
    },
    {
      "id": "task13",
      "title": "Prepare a node for maintenance",
      "solution": "# 1. Select a node with VMs\nNODE_TO_DRAIN=$(oc get pods -A -o wide | grep Running | grep -v -e infra -e openshift | awk 'NR==1 {print $8}')\n\n# 2. Ensure VMs on node have eviction strategy (this would be done on each VM)\n# oc patch vm <vm-name> -n <namespace> --type merge -p '{\"spec\":{\"template\":{\"spec\":{\"evictionStrategy\":\"LiveMigrate\"}}}}'\n\n# 3. Drain node\noc adm drain $NODE_TO_DRAIN --ignore-daemonsets --delete-local-data\n\n# 4. Uncordon node\noc adm uncordon $NODE_TO_DRAIN\n",
      "sections": [
        {
          "title": "Node Drain",
          "notice": "A worker node needs to be rebooted. Safely drain it of all VMs.",
          "subtasks": [
            "Select a worker node running at least one VM.",
            "Ensure the VMs on the node have a live migration eviction strategy.",
            "Use 'oc adm drain' to gracefully evict all VMs from the node.",
            "Uncordon the node after the maintenance is complete."
          ]
        }
      ]
    },
    {
      "id": "task14",
      "title": "Backup the entire multi-tier application using OADP",
      "solution": "# 1. Create Backup CR\noc create -f - -n openshift-adp <<EOF\napiVersion: velero.io/v1\nkind: Backup\nmetadata:\n  name: full-app-backup\nspec:\n  includedNamespaces:\n  - frontend-prod\n  - api-prod\n  - db-prod\n  snapshotVolumes: true\nEOF\n\n# 2. Verify Backup\noc get backup full-app-backup -n openshift-adp -w\n\n# 3. Inspect logs (optional)\n# oc logs -n openshift-adp -l component=velero,name=velero-deployment\n\n# 4. Delete backup object\noc delete backup full-app-backup -n openshift-adp\n",
      "sections": [
        {
          "title": "Multi-Namespace Backup",
          "notice": "Create a single backup that includes the 'frontend-prod', 'api-prod', and 'db-prod' namespaces.",
          "subtasks": [
            "Create a 'Backup' resource that includes all three namespaces.",
            "Verify the backup completes successfully.",
            "Inspect the backup logs for any warnings or errors.",
            "Delete the backup object after verification."
          ]
        }
      ]
    },
    {
      "id": "task15",
      "title": "Configure a VM with a Custom Run Strategy",
      "solution": "# 1. Stop the VM if it is running\noc virt stop frontend-vm -n frontend-prod\n\n# 2. Patch the VM with a custom run strategy\noc patch vm frontend-vm -n frontend-prod --type merge -p '{\"spec\":{\"runStrategy\":\"Halted\"}}'\n\n# 3. Verify the run strategy\noc get vm frontend-vm -n frontend-prod -o yaml | grep runStrategy\n",
      "sections": [
        {
          "title": "Custom Run Strategy Configuration",
          "notice": "Configure the 'frontend-vm' to not start automatically.",
          "subtasks": [
            "Stop the 'frontend-vm' VM if it is running.",
            "Modify the VM definition to set the runStrategy to 'Halted'.",
            "Verify that the runStrategy has been updated.",
            "Attempt to start the VM and verify it does not start automatically."
          ]
        }
      ]
    },
    {
      "id": "task16",
      "title": "Migrate a VM from an External Hypervisor",
      "solution": "# 1. Create Namespace\noc create namespace migrated-vm-ns\n\n# 2. Install Operator\n# This is done via OperatorHub in the UI. Find 'Migration Toolkit for Virtualization' and install.\n\n# 3. Create Provider Secret and CR\noc create secret generic provider-secret --from-literal=user=provider-user --from-literal=password=provider-pass --from-literal=url=https://provider.example.com/sdk -n migrated-vm-ns\n\noc create -f - -n migrated-vm-ns <<EOF\napiVersion: forklift.konveyor.io/v1beta1\nkind: Provider\nmetadata:\n  name: external-provider\nspec:\n  type: vsphere\n  url: https://provider.example.com/sdk\n  secret:\n    name: provider-secret\n    namespace: migrated-vm-ns\nEOF\n\n# 4. Create Plan and execute\noc create -f - -n migrated-vm-ns <<EOF\napiVersion: forklift.konveyor.io/v1beta1\nkind: Plan\nmetadata:\n  name: vm-migration-plan\nspec:\n  provider:\n    source:\n      name: external-provider\n    destination:\n      name: host\n  map:\n    network:\n      - source:\n          name: \"VM Network\"\n        destination:\n          name: pod\n    storage:\n      - source:\n          name: \"datastore1\"\n        destination:\n          storageClass: <default-storage-class>\n  vms:\n  - name: vm-to-migrate\nEOF\n\noc create -f - -n migrated-vm-ns <<EOF\napiVersion: forklift.konveyor.io/v1beta1\nkind: Migration\nmetadata:\n  name: vm-migration\nspec:\n  plan:\n    name: vm-migration-plan\nEOF\n",
      "sections": [
        {
          "title": "VM Migration with MTV",
          "notice": "Migrate a VM named 'vm-to-migrate' from a simulated external hypervisor into a new namespace 'migrated-vm-ns'.",
          "subtasks": [
            "Create a new namespace named 'migrated-vm-ns'.",
            "Install the 'Migration Toolkit for Virtualization' Operator.",
            "Configure a 'Provider' resource to connect to the mock external hypervisor.",
            "Create a 'Plan' to migrate the 'vm-to-migrate' VM, mapping source networks and datastores.",
            "Execute the migration and verify the new VM is running in the 'migrated-vm-ns' namespace."
          ]
        }
      ]
    },
    {
      "id": "task17",
      "title": "Create a VM from a qcow2 URL",
      "solution": "# 1. Create DataVolume\noc create -f - -n default <<EOF\napiVersion: cdi.kubevirt.io/v1beta1\nkind: DataVolume\nmetadata:\n  name: fedora-dv\nspec:\n  source:\n    http:\n      url: https://download.fedoraproject.org/pub/fedora/linux/releases/36/Cloud/x86_64/images/Fedora-Cloud-Base-36-1.5.x86_64.qcow2\n  pvc:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: 10Gi\nEOF\n\n# 2. Create VM\noc create -f - -n default <<EOF\napiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: vm-from-qcow2\nspec:\n  running: true\n  template:\n    spec:\n      domain:\n        devices:\n          disks:\n          - name: rootdisk\n            disk:\n              bus: virtio\n        resources:\n          requests:\n            memory: 2Gi\n      volumes:\n      - name: rootdisk\n        dataVolume:\n          name: fedora-dv\nEOF",
      "sections": [
        {
          "title": "Create VM from qcow2 URL",
          "notice": "Create a new VM in the default namespace from a qcow2 URL.",
          "subtasks": [
            "Create a DataVolume named 'fedora-dv' that imports the Fedora 36 cloud image from 'https://download.fedoraproject.org/pub/fedora/linux/releases/36/Cloud/x86_64/images/Fedora-Cloud-Base-36-1.5.x86_64.qcow2'.",
            "Create a VM named 'vm-from-qcow2' that uses the DataVolume.",
            "Ensure the VM is running.",
            "Verify that you can access the VM's console."
          ]
        }
      ]
    }
  ]
}